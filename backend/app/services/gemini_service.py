"""
Gemini AI Service
Handles interactions with Google Gemini API with Function Calling support
"""
from typing import List, Dict, Optional, Any
import logging
from datetime import datetime
import json

logger = logging.getLogger(__name__)

# Try to import google.generativeai
try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    logger.warning("google-generativeai package not installed. AI features will be disabled.")
    genai = None
    GEMINI_AVAILABLE = False

# Models to try in order (newest to oldest for fallback)
MODELS_TO_TRY = [
    "gemini-2.5-flash-lite",  # Unlimited RPM, best for SQL generation
    "gemini-2.5-flash",
]


class GeminiService:
    """Gemini AI Service with Function Calling support"""
    
    def __init__(self):
        if not GEMINI_AVAILABLE:
            logger.warning("Gemini AI not available")
    
    def generate_response(
        self,
        user_message: str,
        api_key: str,
        context: Dict[str, Any] = None,
        user_role: str = 'staff',
        conversation_history: List[Dict] = None,
        ai_functions=None,  # AIFunctions instance for executing functions
        sql_mode: bool = False  # Enable SQL generation mode
    ) -> Dict[str, Any]:
        """Generate AI response with function calling support"""
        
        if not GEMINI_AVAILABLE:
            return {
                "message": "Dá»‹ch vá»¥ AI khÃ´ng kháº£ dá»¥ng.",
                "error": "AI service not available"
            }
        
        if not api_key or not api_key.strip():
            return {
                "message": "Vui lÃ²ng cung cáº¥p API key.",
                "error": "API key required"
            }
        
        # Configure API
        genai.configure(api_key=api_key.strip())
        
        # Build system prompt
        system_prompt = self._build_system_prompt(user_role, context or {}, sql_mode=sql_mode)
        
        # Build tools for function calling (skip if SQL mode)
        tools = None if sql_mode else self._build_tools(user_role)
        
        # Try models with fallback
        last_error = None
        
        for model_name in MODELS_TO_TRY:
            try:
                logger.info(f"Trying model: {model_name}")
                
                # Create model without system_instruction (use it in chat instead)
                model = genai.GenerativeModel(model_name)
                
                # Build chat history with system prompt as first message
                chat_history = []
                if system_prompt:
                    chat_history.append({
                        "role": "user",
                        "parts": [{"text": "System: " + system_prompt}]
                    })
                    chat_history.append({
                        "role": "model",
                        "parts": [{"text": "Understood. I will assist as described."}]
                    })
                
                # Add conversation history
                if conversation_history:
                    for msg in conversation_history[-10:]:
                        chat_history.append({
                            "role": "user" if msg.get("role") == "user" else "model",
                            "parts": [{"text": msg.get("content", "")}]
                        })
                
                # Start chat and send message
                chat = model.start_chat(history=chat_history)
                response = chat.send_message(user_message)
                
                # Extract text response
                response_text = self._extract_text(response)
                
                logger.info(f"Success with model: {model_name}")
                
                return {
                    "message": response_text,
                    "timestamp": datetime.now().isoformat(),
                    "model": model_name
                }
                
            except Exception as e:
                error_str = str(e)
                logger.warning(f"Model {model_name} failed: {error_str}")
                last_error = error_str
                
                # Retry on rate limit or model not found
                if any(x in error_str.lower() for x in ['429', 'quota', 'rate limit', '404', 'not found']):
                    continue
                break
        
        # All models failed
        return self._handle_error(last_error)
    
    def _build_system_prompt(self, user_role: str, context: Dict, sql_mode: bool = False) -> str:
        """Build system instruction for the AI"""
        user_info = context.get('user', {})
        department = context.get('department', {})
        
        if sql_mode:
            # SQL Generation Mode
            from app.utils.sql_validator import DATABASE_SCHEMA
            
            prompt = f"""Báº¡n lÃ  SQL Query Generator cho há»‡ thá»‘ng QStream - Quáº£n lÃ½ hÃ ng Ä‘á»£i thÃ´ng minh.

THÃ”NG TIN NGÆ¯á»œI DÃ™NG:
- TÃªn: {user_info.get('full_name', 'N/A')}
- Vai trÃ²: {user_role}
- PhÃ²ng ban ID: {context.get('user', {}).get('department_id', 'N/A')}

{DATABASE_SCHEMA}

=== HÆ¯á»šNG DáºªN Táº O SQL ===

1. Khi ngÆ°á»i dÃ¹ng há»i vá» dá»¯ liá»‡u, phÃ¢n tÃ­ch cÃ¢u há»i vÃ  táº¡o SQL query phÃ¹ há»£p
2. CHá»ˆ Táº O SELECT queries, KHÃ”NG Ä‘Æ°á»£c dÃ¹ng INSERT/UPDATE/DELETE/DROP
3. Format response theo cáº¥u trÃºc:
   ```sql
   [SQL_QUERY_HERE]
   ```
   Sau Ä‘Ã³ giáº£i thÃ­ch ngáº¯n gá»n báº±ng tiáº¿ng Viá»‡t

4. LÆ°u Ã½ báº£o máº­t:
   - Staff chá»‰ tháº¥y data cá»§a mÃ¬nh: WHERE staff_id = {user_info.get('id')}
   - Manager tháº¥y data phÃ²ng ban: JOIN vá»›i users WHERE department_id = {context.get('user', {}).get('department_id')}

5. Examples:
   User: "HÃ ng Ä‘á»£i cÃ³ bao nhiÃªu ngÆ°á»i?"
   Response:
   ```sql
   SELECT COUNT(*) as total FROM queue_tickets WHERE status = 'waiting'
   ```
   Äang cÃ³ X ngÆ°á»i chá» trong hÃ ng Ä‘á»£i.

   User: "Top 3 nhÃ¢n viÃªn xuáº¥t sáº¯c?"
   Response:
   ```sql
   SELECT u.full_name, sp.avg_rating, sp.tickets_served 
   FROM staff_performance sp 
   JOIN users u ON sp.staff_id = u.id 
   ORDER BY sp.avg_rating DESC LIMIT 3
   ```
   ÄÃ¢y lÃ  3 nhÃ¢n viÃªn cÃ³ rating cao nháº¥t.

6. Náº¿u cÃ¢u há»i KHÃ”NG liÃªn quan Ä‘áº¿n data (vÃ­ dá»¥: chÃ o há»i, há»i vá» tÃ­nh nÄƒng), 
   tráº£ lá»i bÃ¬nh thÆ°á»ng KHÃ”NG cáº§n táº¡o SQL.

LUÃ”N Äáº¶T SQL query trong code block ```sql ... ``` Ä‘á»ƒ backend cÃ³ thá»ƒ extract.
"""
        else:
            # Normal chat mode
            prompt = f"""Báº¡n lÃ  AI Helper cá»§a há»‡ thá»‘ng QStream - Quáº£n lÃ½ hÃ ng Ä‘á»£i thÃ´ng minh.

THÃ”NG TIN NGÆ¯á»œI DÃ™NG:
- TÃªn: {user_info.get('full_name', 'N/A')}
- Username: {user_info.get('username', 'N/A')}
- Vai trÃ²: {user_role}
- PhÃ²ng ban: {department.get('name', 'N/A')}

Há»† THá»NG QSTREAM CÃ“ CÃC TÃNH NÄ‚NG:
1. Quáº£n lÃ½ hÃ ng Ä‘á»£i - Gá»i phiáº¿u, phá»¥c vá»¥ khÃ¡ch hÃ ng
2. Lá»‹ch lÃ m viá»‡c - Xem ca lÃ m viá»‡c Ä‘Æ°á»£c phÃ¢n cÃ´ng
3. Hiá»‡u suáº¥t - Xem thá»‘ng kÃª phá»¥c vá»¥ vÃ  Ä‘Ã¡nh giÃ¡

HÆ¯á»šNG DáºªN TRáº¢ Lá»œI:
- Tráº£ lá»i thÃ¢n thiá»‡n, ngáº¯n gá»n báº±ng tiáº¿ng Viá»‡t
- HÆ°á»›ng dáº«n ngÆ°á»i dÃ¹ng cÃ¡ch sá»­ dá»¥ng há»‡ thá»‘ng
- Náº¿u ngÆ°á»i dÃ¹ng há»i vá» dá»¯ liá»‡u cá»¥ thá»ƒ (sá»‘ khÃ¡ch, lá»‹ch, hiá»‡u suáº¥t), hÆ°á»›ng dáº«n há» xem trá»±c tiáº¿p trÃªn dashboard hoáº·c tab tÆ°Æ¡ng á»©ng
- KhÃ´ng bá»‹a sá»‘ liá»‡u khi khÃ´ng cÃ³ thÃ´ng tin
"""
            
            if user_role == 'manager':
                prompt += """
Báº N ÄANG Há»– TRá»¢ QUáº¢N LÃ, CÃ“ THÃŠM QUYá»€N:
- Xem thÃ´ng tin táº¥t cáº£ nhÃ¢n viÃªn
- PhÃ¢n ca lÃ m viá»‡c
- Xem bÃ¡o cÃ¡o phÃ²ng ban
"""
        
        return prompt
    
    def _build_tools(self, user_role: str):
        """Build tool definitions for function calling"""
        from .ai_functions import TOOL_DECLARATIONS
        
        # Filter tools based on role
        allowed_tools = TOOL_DECLARATIONS.copy()
        
        if user_role != 'manager':
            # Remove manager-only tools for staff
            manager_only = ['get_department_stats', 'get_all_staff_status']
            allowed_tools = [t for t in allowed_tools if t['name'] not in manager_only]
        
        # Return in Gemini API format - list of function declarations
        # Gemini SDK accepts list of dicts directly as tools
        if not allowed_tools:
            return None
        
        return allowed_tools
    
    def _build_chat_history(self, conversation_history: List[Dict] = None) -> List:
        """Build chat history for Gemini"""
        history = []
        
        for msg in (conversation_history or [])[-10:]:
            role = msg.get('role', 'user')
            content = msg.get('content', msg.get('message', ''))
            
            gemini_role = 'user' if role == 'user' else 'model'
            history.append({
                'role': gemini_role,
                'parts': [content]
            })
        
        return history
    
    def _extract_text(self, response) -> str:
        """Extract text from Gemini response"""
        if hasattr(response, 'text'):
            return response.text
        elif hasattr(response, 'candidates') and response.candidates:
            parts = response.candidates[0].content.parts
            texts = [p.text for p in parts if hasattr(p, 'text')]
            return '\n'.join(texts) if texts else str(response)
        return str(response)
    
    def _handle_error(self, error: str) -> Dict[str, Any]:
        """Handle errors and return appropriate response"""
        if not error:
            error = "Unknown error"
        
        if '429' in error or 'quota' in error.lower() or 'rate limit' in error.lower():
            return {
                "message": "âš ï¸ **API Key Ä‘Ã£ háº¿t quota sá»­ dá»¥ng**\n\nVui lÃ²ng:\n1. Äá»£i 1-2 phÃºt rá»“i thá»­ láº¡i\n2. Hoáº·c sá»­ dá»¥ng API key khÃ¡c (click 'ğŸ”‘ Cáº¥u hÃ¬nh API Key')\n3. Hoáº·c kiá»ƒm tra quota táº¡i: https://ai.google.dev/pricing",
                "error": "RATE_LIMIT_EXCEEDED"
            }
        
        if '403' in error or 'API key' in error or 'invalid' in error.lower():
            return {
                "message": "âŒ **API key khÃ´ng há»£p lá»‡**\n\nVui lÃ²ng:\n1. Click 'ğŸ”‘ Cáº¥u hÃ¬nh API Key' Ä‘á»ƒ cáº­p nháº­t\n2. Láº¥y key má»›i táº¡i: https://aistudio.google.com/apikey\n3. Äáº£m báº£o key Ä‘Ã£ Ä‘Æ°á»£c activate",
                "error": "INVALID_API_KEY"
            }
        
        return {
            "message": f"ÄÃ£ xáº£y ra lá»—i: {error}",
            "error": error
        }


# Service instance
gemini_service = GeminiService()
